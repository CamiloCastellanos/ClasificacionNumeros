{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificación Números Red Neuronal Convolucional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiwrkWVZOcp7/6ykW/vvyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamiloCastellanos/ClasificacionNumeros/blob/main/Redes%20Neuronales%20Convolucionales/Clasificaci%C3%B3n_N%C3%BAmeros_Red_Neuronal_Convolucional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOD_UedBCPnx"
      },
      "source": [
        "# La Fuente es el canal de Youtube \"Ringa Tech\"\n",
        "# El video fue https://youtu.be/eGDSlW93Bng\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Cargar los datos de MNIST\n",
        "#Aqui lo hago de otra manera porque es mas simple para poder usar el modulo de aumento de datos\n",
        "#de Keras de esta manera\n",
        "#(X_entrenamiento, Y_entrenamiento), (X_pruebas, Y_pruebas) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7U5V_d3DDBV"
      },
      "source": [
        "\n",
        "#Descargar set de datos de MNIST (Numeros escritos a mano, etiquetados)\n",
        "datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)\n",
        "\n",
        "#Obtener en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
        "datos_entrenamiento, datos_pruebas = datos['train'], datos['test']\n",
        "\n",
        "#Funcion de normalizacion para los datos (Pasar valor de los pixeles de 0-255 a 0-1)\n",
        "#(Hace que la red aprenda mejor y mas rapido)\n",
        "def normalizar(imagenes, etiquetas):\n",
        "  imagenes = tf.cast(imagenes, tf.float32)\n",
        "  imagenes /= 255 #Aqui se pasa de 0-255 a 0-1\n",
        "  return imagenes, etiquetas\n",
        "\n",
        "#Normalizar los datos de entrenamiento con la funcion que hicimos\n",
        "datos_entrenamiento = datos_entrenamiento.map(normalizar)\n",
        "datos_pruebas = datos_pruebas.map(normalizar)\n",
        "\n",
        "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
        "datos_entrenamiento = datos_entrenamiento.cache()\n",
        "datos_pruebas = datos_pruebas.cache()\n",
        "\n",
        "clases = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tQzOyycD5xC"
      },
      "source": [
        "dddd"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}